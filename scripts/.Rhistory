) %>%
pull(meadow_num) %>%
t() # make a row vector
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 1,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 10,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 0.01,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 5,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 2,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 1,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 2,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
lambdas <- seq(0.001,2,length.out = 100)
lambdas
years <- unique(butterfly$year)
years
fit <- lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 2,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
predict(fitr)
predict(fit)
fit$fitted.values
fit <- lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 1,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = TRUE)
fit$fitted.values
fit$beta
fit$Psi
fit$u
fit <- lassop(data = X,Y = y,z = Z,grp = grp,D = TRUE,mu = 1,step = 3000,fix = 1,rand = 1,alpha = 0.5,showit = FALSE,penalty.factor = rep(1,ncol(X)))
beta_fix <- fit$beta
beta_rand <- fit$u
beta_rand
iyear = 200
iyear = 2005
training <- butterfly_long %>%
filter(year != iyear)
validating <- butterfly_long %>%
filter(year == iyear)
y <- training %>%
spread(covariate, value) %>%
pull(Rt)
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y)), .)
Z <- X[,1,drop = FALSE]
grp <- training %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
training <- butterfly_long %>%
filter(year != iyear)
validating <- butterfly_long %>%
filter(year == iyear)
y <- training %>%
spread(covariate, value) %>%
pull(Rt)
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y)), .)
Z <- X[,1,drop = FALSE]
grp <- training %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
fit <- lassop(
data = X,
Y = y,
z = Z,
grp = grp,
D = TRUE,
mu = 1,
step = 3000,
fix = 1,
rand = 1,
alpha = 0.5,
showit = FALSE,
penalty.factor = rep(1,ncol(X))
)
beta_fix <- fit$beta # fixed effects
beta_rand <- fit$u # random effects offsets (on intercept)
# Generate predictions
y_loo <- validating %>%
spread(covariate, value) %>%
pull(Rt)
X_loo <- validating %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y)), .)
Z_loo <- X_loo[,1,drop = FALSE]
grp_loo <- validating %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
# Generate predictions
y_loo <- validating %>%
spread(covariate, value) %>%
pull(Rt)
X_loo <- validating %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y_loo)), .)
Z_loo <- X_loo[,1,drop = FALSE]
grp_loo <- validating %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
Z
grp_loo
Z_loo
beta_rand
Z_loo*beta_rand
X_loo*beta_fix
X_loo%*%beta_fix
X_loo
beta_fix
X_loo%*%beta_fix + Z_loo*beta_rand
y_loo
grp
pred_df <- data.frame(out_year = iyear,
meadow_num = 1:11,
Rt_obs = y_loo,
Rt_hat = y_hat)
y_hat <- X_loo%*%beta_fix + Z_loo*beta_rand
# Store results
pred_df <- data.frame(out_year = iyear,
meadow_num = 1:11,
Rt_obs = y_loo,
Rt_hat = y_hat)
pred_df
## predict_butterflies.R
##    R script that reproduces our "prediction" analysis of the Roland and
##    Matter apline butterfly data. We seek the optimally predictive model
##    that can be used to predict the 2015 population abundances, as in
##    Matter and Roland (2015, Ecosphere).
# Preliminaries -----------------------------------------------------------
rm(list = ls(all.names = TRUE))
# Load packages -----------------------------------------------------------
library(modselr)
# devtools::install_github('atredennick/modselr') # for the butterfly data
library(tidyverse)
library(ggthemes)
library(MMS) # for mixed effects regularization
# Reformat the data -------------------------------------------------------
butterfly_long <- butterfly %>%
filter(year < 2014) %>%
select_if(~ !any(is.na(.))) %>% # remove columns with NA
gather(covariate, value, -year, -Rt, -meada)
butterfly_to_predict <- butterfly %>%
filter(year == 2014) %>%
dplyr::select(year, meada, Nt, logNt)
# Format data for elastic net ---------------------------------------------
# Perform cross-validation over grid of penalties -------------------------
lambdas <- seq(0.001,2,length.out = 10)
years <- unique(butterfly$year)
pred_df <- {}
for(iyear in years){
training <- butterfly_long %>%
filter(year != iyear)
validating <- butterfly_long %>%
filter(year == iyear)
y <- training %>%
spread(covariate, value) %>%
pull(Rt)
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y)), .)
Z <- X[,1,drop = FALSE]
grp <- training %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
y_loo <- validating %>%
spread(covariate, value) %>%
pull(Rt)
X_loo <- validating %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y_loo)), .)
Z_loo <- X_loo[,1,drop = FALSE]
for(ilambda in lambdas){
fit <- lassop(
data = X,
Y = y,
z = Z,
grp = grp,
D = TRUE,
mu = 1,
step = 3000,
fix = 1,
rand = 1,
alpha = 0.5,
showit = FALSE,
penalty.factor = rep(1,ncol(X))
)
beta_fix <- fit$beta # fixed effects
beta_rand <- fit$u # random effects offsets (on intercept)
# Generate predictions
y_hat <- X_loo%*%beta_fix + Z_loo*beta_rand
# Store results
temp_df <- data.frame(lambda = ilambda,
out_year = iyear,
meadow_num = 1:11,
Rt_obs = y_loo,
Rt_hat = y_hat)
pred_df <- rbind(pred_df, temp_df)
}
}
iyear
ilambda
pred_df
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
cbind(rep(1,length(y)), .) %>%
scale()
X
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix() %>%
scale() %>%
cbind(rep(1,length(y)), .)
X
X_sd <- apply(X, MARGIN = 2, FUN = sd)
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix()
X_means <- colMeans(X)
X_sd <- apply(X, MARGIN = 2, FUN = sd)
X_loo <- validating %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix()
X_loo <- validating %>%
spread(covariate, value)
validating
iyear=2005
training <- butterfly_long %>%
filter(year != iyear)
validating <- butterfly_long %>%
filter(year == iyear)
y <- training %>%
spread(covariate, value) %>%
pull(Rt)
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix()
X_means <- colMeans(X)
X_sd <- apply(X, MARGIN = 2, FUN = sd)
X <- X %>%
scale() %>%
cbind(rep(1,length(y)), .)
Z <- X[,1,drop = FALSE]
grp <- training %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
y_loo <- validating %>%
spread(covariate, value) %>%
pull(Rt)
X_loo <- validating %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix()
for(k in 1:ncol(X_loo)){
X_loo[,k] <- (X_loo[,k] - X_means[k])/X_sds[k]
}
for(k in 1:ncol(X_loo)){
X_loo[,k] <- (X_loo[,k] - X_means[k])/X_sd[k]
}
X_loo
source('~/Repos/drivers/Lemonade_Simulations/empirical/alpine_butterflies/predict_butterflies.R')
pred_df
mse_df <- pred_df %>%
mutate(
sq_err = (Rt_obs - Rt_hat)^2
)
mse_df <- pred_df %>%
mutate(
sq_err = (Rt_obs - Rt_hat)^2
) %>%
group_by(lambda, meadow_num) %>%
summarise(MSE = mean(sq_err))
mse_df
ggplot(mse_df, aes(x = lambda, y = MSE, color = meadow_num))+
geom_line()
ggplot(mse_df, aes(x = lambda, y = MSE, color = as.factor(meadow_num)))+
geom_line()
ggplot(mse_df, aes(x = lambda, y = MSE))+
geom_line()+
facet_wrap(~meadow_num, scales = "free")
source('~/Repos/drivers/Lemonade_Simulations/empirical/alpine_butterflies/predict_butterflies.R')
## predict_butterflies.R
##    R script that reproduces our "prediction" analysis of the Roland and
##    Matter apline butterfly data. We seek the optimally predictive model
##    that can be used to predict the 2015 population abundances, as in
##    Matter and Roland (2015, Ecosphere).
# Preliminaries -----------------------------------------------------------
rm(list = ls(all.names = TRUE))
# Load packages -----------------------------------------------------------
library(modselr)
# devtools::install_github('atredennick/modselr') # for the butterfly data
library(tidyverse)
library(ggthemes)
library(MMS) # for mixed effects regularization
# Reformat the data -------------------------------------------------------
butterfly_long <- butterfly %>%
filter(year < 2014) %>%
select_if(~ !any(is.na(.))) %>% # remove columns with NA
gather(covariate, value, -year, -Rt, -meada)
butterfly_to_predict <- butterfly %>%
filter(year == 2014) %>%
dplyr::select(year, meada, Nt, logNt)
# Format data for elastic net ---------------------------------------------
# Perform cross-validation over grid of penalties -------------------------
lambdas <- seq(0.01,2,length.out = 10)
years <- unique(butterfly_long$year)
pred_df <- {}
for(iyear in years){
training <- butterfly_long %>%
filter(year != iyear)
validating <- butterfly_long %>%
filter(year == iyear)
y <- training %>%
spread(covariate, value) %>%
pull(Rt)
X <- training %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix()
X_means <- colMeans(X)
X_sd <- apply(X, MARGIN = 2, FUN = sd)
X <- X %>%
scale() %>%
cbind(rep(1,length(y)), .)
Z <- X[,1,drop = FALSE]
grp <- training %>%
spread(covariate, value) %>%
mutate(
meadow_num = as.numeric(as.factor(meada))
) %>%
pull(meadow_num) %>%
t() # make a row vector
y_loo <- validating %>%
spread(covariate, value) %>%
pull(Rt)
X_loo <- validating %>%
spread(covariate, value) %>%
dplyr::select(-year, -meada, -Rt) %>%
as.matrix()
for(k in 1:ncol(X_loo)){
X_loo[,k] <- (X_loo[,k] - X_means[k])/X_sd[k]
}
X_loo <- X_loo %>%
cbind(rep(1,length(y_loo)), .)
Z_loo <- X_loo[,1,drop = FALSE]
for(ilambda in lambdas){
fit <- lassop(
data = X,
Y = y,
z = Z,
grp = grp,
D = TRUE,
mu = ilambda,
step = 3000,
fix = 1,
rand = 1,
alpha = 0.5,
showit = FALSE,
penalty.factor = rep(1,ncol(X))
)
beta_fix <- fit$beta # fixed effects
beta_rand <- fit$u # random effects offsets (on intercept)
# Generate predictions
y_hat <- X_loo%*%beta_fix + Z_loo*beta_rand
# Store results
temp_df <- data.frame(lambda = ilambda,
out_year = iyear,
meadow_num = 1:11,
Rt_obs = y_loo,
Rt_hat = y_hat)
pred_df <- rbind(pred_df, temp_df)
}
}
# Calculate MSEs ----------------------------------------------------------
mse_df <- pred_df %>%
mutate(
sq_err = (Rt_obs - Rt_hat)^2
) %>%
group_by(lambda, meadow_num) %>%
summarise(MSE = mean(sq_err))
ggplot(mse_df, aes(x = lambda, y = MSE))+
geom_line()+
facet_wrap(~meadow_num, scales = "free")
ggplot(mse_df, aes(x = log(lambda), y = MSE))+
geom_line()+
facet_wrap(~meadow_num, scales = "free")
## test_analysis.R: This is a sandbox to see if we can do the IAR analysis
##    in R. Hopefully this script will get ported into a complete analysis.
# Load libraries ----------------------------------------------------------
library(data.table)
library(raster)
library(sp)
library(rgdal)
setwd("~/Repos/conus_npp_var/scripts")
all_files <- list.files("../data/")
## test_analysis.R: This is a sandbox to see if we can do the IAR analysis
##    in R. Hopefully this script will get ported into a complete analysis.
# Load libraries ----------------------------------------------------------
library(data.table)
library(raster)
library(sp)
library(rgdal)
# Read in data ------------------------------------------------------------
all_files <- list.files("../data/")
test <- raster(all_files[1])
## test_analysis.R: This is a sandbox to see if we can do the IAR analysis
##    in R. Hopefully this script will get ported into a complete analysis.
# Load libraries ----------------------------------------------------------
library(data.table)
library(raster)
library(sp)
library(rgdal)
# Read in data ------------------------------------------------------------
data_dir <- "../data/"
all_files <- list.files(data_dir)
fname <- paste0(data_dir,all_files[1])
test <- raster(fname)
test
plot(test)
n = 4
mat = matrix(1:n^2, nrow = n)
mat.pad = rbind(NA, cbind(NA, mat, NA), NA)
mat
mat.pad
ind = 2:(n + 1) # row/column indices of the "middle"
ind
neigh = rbind(N  = as.vector(mat.pad[ind - 1, ind    ]),
NE = as.vector(mat.pad[ind - 1, ind + 1]),
E  = as.vector(mat.pad[ind    , ind + 1]),
SE = as.vector(mat.pad[ind + 1, ind + 1]),
S  = as.vector(mat.pad[ind + 1, ind    ]),
SW = as.vector(mat.pad[ind + 1, ind - 1]),
W  = as.vector(mat.pad[ind    , ind - 1]),
NW = as.vector(mat.pad[ind - 1, ind - 1]))
neigh
mat = matrix(1:50^2, nrow = 50)
mrip = function(mat) {
m2<-cbind(NA,rbind(NA,mat,NA),NA)
addresses <- expand.grid(x = 1:4, y = 1:4)
ret <- c()
for(i in 1:-1)
for(j in 1:-1)
if(i!=0 || j !=0)
ret <- rbind(ret,m2[addresses$x+i+1+nrow(m2)*(addresses$y+j)])
return(ret)
}
neigh <- mrip(mat)
neigh
mat = matrix(1:50^2, nrow = 50)
mrip = function(mat) {
m2<-cbind(NA,rbind(NA,mat,NA),NA)
addresses <- expand.grid(x = 1:nrow(mat), y = 1:nrow(mat))
ret <- c()
for(i in 1:-1)
for(j in 1:-1)
if(i!=0 || j !=0)
ret <- rbind(ret,m2[addresses$x+i+1+nrow(m2)*(addresses$y+j)])
return(ret)
}
neigh <- mrip(mat)
neigh
n = 4
mat = matrix(1:n^2, nrow = n)
mat.pad = rbind(NA, cbind(NA, mat, NA), NA)
ind = 2:(n + 1) # row/column indices of the "middle"
neigh = rbind(N  = as.vector(mat.pad[ind - 1, ind    ]),
NE = as.vector(mat.pad[ind - 1, ind + 1]),
E  = as.vector(mat.pad[ind    , ind + 1]),
SE = as.vector(mat.pad[ind + 1, ind + 1]),
S  = as.vector(mat.pad[ind + 1, ind    ]),
SW = as.vector(mat.pad[ind + 1, ind - 1]),
W  = as.vector(mat.pad[ind    , ind - 1]),
NW = as.vector(mat.pad[ind - 1, ind - 1]))
neigh
mat[neigh[1]]
mat
